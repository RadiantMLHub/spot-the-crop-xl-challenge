{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S1Test_Observation1",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbiEDNVkEG3T"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp8vMTsAGani",
        "outputId": "265ed585-88f4-4deb-8312-25aeeedc3e36"
      },
      "source": [
        "!git clone 'https://github.com/radiantearth/mlhub-tutorials.git'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlhub-tutorials'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Counting objects: 100% (337/337), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 479 (delta 200), reused 191 (delta 91), pack-reused 142\u001b[K\n",
            "Receiving objects: 100% (479/479), 39.15 MiB | 25.68 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MzJvZxGakE",
        "outputId": "fb919f15-d6be-42ec-d5e5-821361323034"
      },
      "source": [
        "!pip install -r '/content/mlhub-tutorials/notebooks/South Africa Crop Types Competition/requirements.txt' -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.9 MB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 34.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 79 kB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 47 kB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 857 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFLc43syf6x"
      },
      "source": [
        "exit(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-RSB5omEInc"
      },
      "source": [
        "# LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-xKDNhkyhTZ"
      },
      "source": [
        "# Required libraries\n",
        "import os\n",
        "import tarfile\n",
        "import json\n",
        "from pathlib import Path\n",
        "from radiant_mlhub.client import _download as download_file\n",
        "\n",
        "import datetime\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "os.environ['MLHUB_API_KEY'] = '96f33e4c9510d0d369d881c6fdefa91502829db09f41e0c92cba8b02fede920b'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S1h19sfEKEr"
      },
      "source": [
        "# DOWNLOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBqBu3cMyjQA"
      },
      "source": [
        "DOWNLOAD_S1 = True # If you set this to true then the Sentinel-1 data will be downloaded which is not needed in this notebook.\n",
        "\n",
        "# Select which imagery bands you'd like to download here:\n",
        "DOWNLOAD_BANDS = {\n",
        "    'B01': False,\n",
        "    'B02': False,\n",
        "    'B03': False,\n",
        "    'B04': False,\n",
        "    'B05': False,\n",
        "    'B06': False,\n",
        "    'B07': False,\n",
        "    'B08': False,\n",
        "    'B8A': False,\n",
        "    'B09': False,\n",
        "    'B11': False,\n",
        "    'B12': False,\n",
        "    'CLM': False\n",
        "}\n",
        "\n",
        "# In this model we will only use Green, Red and NIR bands. You can select to download any number of bands. \n",
        "# Our choice relies on the fact that vegetation is most sensitive to these bands. \n",
        "# We also donwload the CLM or Cloud Mask layer to exclude cloudy data from the training phase. \n",
        "# You can also do a feature selection, and try different combination of bands to see which ones will result in a better accuracy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g68iGaSgylS4"
      },
      "source": [
        "FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
        "\n",
        "def download_archive(archive_name):\n",
        "    if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
        "        return\n",
        "    \n",
        "    print(f'Downloading {archive_name} ...')\n",
        "    download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
        "    download_file(download_url, '.')\n",
        "    print(f'Extracting {archive_name} ...')\n",
        "    with tarfile.open(archive_name) as tfile:\n",
        "        tfile.extractall()\n",
        "    os.remove(archive_name)\n",
        "\n",
        "for split in ['test']:\n",
        "    # Download the labels\n",
        "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
        "    download_archive(labels_archive)\n",
        "    \n",
        "    # Download Sentinel-1 data\n",
        "    if DOWNLOAD_S1:\n",
        "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
        "        download_archive(s1_archive)\n",
        "        \n",
        "\n",
        "    for band, download in DOWNLOAD_BANDS.items():\n",
        "        if not download:\n",
        "            continue\n",
        "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
        "        download_archive(s2_archive)\n",
        "        \n",
        "def resolve_path(base, path):\n",
        "    return Path(os.path.join(base, path)).resolve()\n",
        "        \n",
        "def load_df(collection_id):\n",
        "    split = collection_id.split('_')[-2]\n",
        "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
        "    rows = []\n",
        "    item_links = []\n",
        "    for link in collection['links']:\n",
        "        if link['rel'] != 'item':\n",
        "            continue\n",
        "        item_links.append(link['href'])\n",
        "        \n",
        "    for item_link in item_links:\n",
        "        item_path = f'{collection_id}/{item_link}'\n",
        "        current_path = os.path.dirname(item_path)\n",
        "        item = json.load(open(item_path, 'r'))\n",
        "        tile_id = item['id'].split('_')[-1]\n",
        "        for asset_key, asset in item['assets'].items():\n",
        "            rows.append([\n",
        "                tile_id,\n",
        "                None,\n",
        "                None,\n",
        "                asset_key,\n",
        "                str(resolve_path(current_path, asset['href']))\n",
        "            ])\n",
        "            \n",
        "        for link in item['links']:\n",
        "            if link['rel'] != 'source':\n",
        "                continue\n",
        "            source_item_id = link['href'].split('/')[-2]\n",
        "            \n",
        "            if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
        "                continue\n",
        "            elif source_item_id.find('_s1_') > 0:\n",
        "                for band in ['VV', 'VH']:\n",
        "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
        "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
        "                    \n",
        "                    rows.append([\n",
        "                        tile_id,\n",
        "                        f'{date}T00:00:00Z',\n",
        "                        's1',\n",
        "                        band,\n",
        "                        asset_path\n",
        "                    ])\n",
        "                \n",
        "            if source_item_id.find('_s2_') > 0:\n",
        "                for band, download in DOWNLOAD_BANDS.items():\n",
        "                    if not download:\n",
        "                        continue\n",
        "                    \n",
        "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
        "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
        "                    rows.append([\n",
        "                        tile_id,\n",
        "                        f'{date}T00:00:00Z',\n",
        "                        's2',\n",
        "                        band,\n",
        "                        asset_path\n",
        "                    ])\n",
        "            \n",
        "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
        "\n",
        "competition_test_df = load_df(f'{FOLDER_BASE}_test_labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-dUI1_AzOHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10cbf2f0-0156-48ba-fa67-e1093fec4479"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDHGa05LEPJD"
      },
      "source": [
        "# CREATE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxPaJy6m6EBg"
      },
      "source": [
        "# This DataFrame lists all types of assets including documentation of the data. \n",
        "# In the following, we will use the Sentinel-2 bands as well as labels. \n",
        "tile_ids_test = competition_test_df['tile_id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG5fN4cI65qQ"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "import gc\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "harn9qwG65oB"
      },
      "source": [
        "n_obs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB2CV1T96Uuh"
      },
      "source": [
        "%%time\n",
        "\n",
        "competition_test_df['Month'] = pd.to_datetime(competition_test_df['datetime']).dt.month\n",
        "X = np.empty((0, 2*8),dtype=np.float16)\n",
        "y = np.empty((0, 1),dtype=np.float16)\n",
        "field_ids = np.empty((0, 1),np.float16)\n",
        "\n",
        "for tile_id in tqdm_notebook(tile_ids_test[0:tile_ids_test.shape[0]]):\n",
        "    tile_df = competition_test_df[competition_test_df['tile_id']==tile_id]\n",
        "    \n",
        "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
        "    field_id_array = field_id_src.read(1).flatten()\n",
        "    nonzeroidx = np.nonzero(field_id_array)[0]\n",
        "    field_ids = np.append(field_ids, field_id_array[nonzeroidx])\n",
        "\n",
        "    tile_date_times = tile_df[tile_df['satellite_platform']=='s1']['Month'].unique().tolist()\n",
        "    X_tile = np.empty((nonzeroidx.shape[0], 0),dtype=np.float16)\n",
        "    n_X = 0\n",
        "    for date_time_idx in range(0,len(tile_date_times)):\n",
        "\n",
        "        vv_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='VV')]['file_path'].values[0])\n",
        "        vv_array = np.expand_dims(vv_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "        \n",
        "        vh_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='VH')]['file_path'].values[0])\n",
        "        vh_array = np.expand_dims(vh_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        X_tile = np.append(X_tile,vv_array,  axis = 1)\n",
        "        X_tile = np.append(X_tile,vh_array,  axis = 1)\n",
        "\n",
        "        del vv_array,vh_array\n",
        "        del vv_src,vh_src\n",
        "    X = np.append(X, X_tile, axis=0)\n",
        "    del X_tile , field_id_array , field_id_src \n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nStutoS0Po_N",
        "outputId": "8578ba50-6b6a-423c-8e28-54de56c8709d"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pONjdGDAW4BM"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5otf8f9CDM85"
      },
      "source": [
        "data = pd.DataFrame(X)\n",
        "data['field_id'] = field_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VXCeF0LPLvN"
      },
      "source": [
        "* **Reduce Memory Usage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF8FnGvhPAuF"
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "  start_mem = df.memory_usage().sum() / 1024**2\n",
        "  for col in df.columns:\n",
        "      col_type = df[col].dtypes\n",
        "      if col_type in numerics:\n",
        "          c_min = df[col].min()\n",
        "          c_max = df[col].max()\n",
        "          if str(col_type)[:3] == 'int':\n",
        "              if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                  df[col] = df[col].astype(np.int8)\n",
        "              elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                  df[col] = df[col].astype(np.int16)\n",
        "              elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                  df[col] = df[col].astype(np.int32)\n",
        "              elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                  df[col] = df[col].astype(np.int64)\n",
        "          else:\n",
        "              if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                  df[col] = df[col].astype(np.float16)\n",
        "              elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float64)\n",
        "\n",
        "  end_mem = df.memory_usage().sum() / 1024**2\n",
        "  print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "  print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UWYy1FHPArw"
      },
      "source": [
        "data = reduce_mem_usage(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNQPTwawf9ul"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHqXT3FRxeE"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-K4HNAaXYph"
      },
      "source": [
        "# Each field has several pixels in the data. Here our goal is to build a Random Forest (RF) model using the average values\n",
        "# of the pixels within each field. So, we use `groupby` to take the mean for each field_id\n",
        "data_grouped = data.groupby('field_id').mean().reset_index()\n",
        "data_grouped = reduce_mem_usage(data_grouped)\n",
        "data_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn2qm85MVHYr"
      },
      "source": [
        "feat = [\"VV\",\"VH\"]\n",
        "columns = [x + '_Month4' for x in feat] + [x + '_Month5' for x in feat] + \\\n",
        "          [x + '_Month6' for x in feat] + [x + '_Month7' for x in feat] + \\\n",
        "          [x + '_Month8' for x in feat] + [x + '_Month9' for x in feat] + \\\n",
        "          [x + '_Month10' for x in feat] + [x + '_Month11' for x in feat] \n",
        "columns = ['field_id'] + columns "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-QIMg0V2tU"
      },
      "source": [
        "data_grouped.columns = columns\n",
        "data_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDGsQHL5R7Ip",
        "outputId": "341e5aa1-f2ab-4d8a-f27e-7d69edcb9034"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtA3TmeUvly"
      },
      "source": [
        "data_grouped.to_csv('S1TestObs1.csv',index=False)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth',exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth/Data',exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth/Data/TestS1',exist_ok=True)\n",
        "\n",
        "!cp 'S1TestObs1.csv' \"/content/drive/MyDrive/RadiantEarth/Data/TestS1/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}