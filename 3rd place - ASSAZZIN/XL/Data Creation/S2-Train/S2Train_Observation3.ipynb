{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S2Train-Observation3",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbiEDNVkEG3T"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp8vMTsAGani",
        "outputId": "7e841ded-46ce-4bff-f1b8-bb02091c3a50"
      },
      "source": [
        "!git clone 'https://github.com/radiantearth/mlhub-tutorials.git'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlhub-tutorials'...\n",
            "remote: Enumerating objects: 479, done.\u001b[K\n",
            "remote: Counting objects: 100% (337/337), done.\u001b[K\n",
            "remote: Compressing objects: 100% (237/237), done.\u001b[K\n",
            "remote: Total 479 (delta 200), reused 191 (delta 91), pack-reused 142\u001b[K\n",
            "Receiving objects: 100% (479/479), 39.15 MiB | 13.04 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MzJvZxGakE",
        "outputId": "bc60bfbe-f0da-4ea5-efb4-5d925b3166b9"
      },
      "source": [
        "!pip install -r '/content/mlhub-tutorials/notebooks/South Africa Crop Types Competition/requirements.txt' -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.9 MB 6.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 42.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 29.2 MB 76 kB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 44 kB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 136 kB 68.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 971 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.5 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YFLc43syf6x"
      },
      "source": [
        "exit(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-RSB5omEInc"
      },
      "source": [
        "# LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-xKDNhkyhTZ"
      },
      "source": [
        "# Required libraries\n",
        "import os\n",
        "import tarfile\n",
        "import json\n",
        "from pathlib import Path\n",
        "from radiant_mlhub.client import _download as download_file\n",
        "\n",
        "import datetime\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "os.environ['MLHUB_API_KEY'] = '96f33e4c9510d0d369d881c6fdefa91502829db09f41e0c92cba8b02fede920b'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S1h19sfEKEr"
      },
      "source": [
        "# DOWNLOAD DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBqBu3cMyjQA"
      },
      "source": [
        "DOWNLOAD_S1 = False # If you set this to true then the Sentinel-1 data will be downloaded which is not needed in this notebook.\n",
        "\n",
        "# Select which imagery bands you'd like to download here:\n",
        "DOWNLOAD_BANDS = {\n",
        "    'B01': True,\n",
        "    'B02': True,\n",
        "    'B03': True,\n",
        "    'B04': True,\n",
        "    'B05': True,\n",
        "    'B06': True,\n",
        "    'B07': True,\n",
        "    'B08': True,\n",
        "    'B8A': True,\n",
        "    'B09': True,\n",
        "    'B11': True,\n",
        "    'B12': True,\n",
        "    'CLM': False\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g68iGaSgylS4"
      },
      "source": [
        "FOLDER_BASE = 'ref_south_africa_crops_competition_v1'\n",
        "\n",
        "def download_archive(archive_name):\n",
        "    if os.path.exists(archive_name.replace('.tar.gz', '')):\n",
        "        return\n",
        "    \n",
        "    print(f'Downloading {archive_name} ...')\n",
        "    download_url = f'https://radiant-mlhub.s3.us-west-2.amazonaws.com/archives/{archive_name}'\n",
        "    download_file(download_url, '.')\n",
        "    print(f'Extracting {archive_name} ...')\n",
        "    with tarfile.open(archive_name) as tfile:\n",
        "        tfile.extractall()\n",
        "    os.remove(archive_name)\n",
        "\n",
        "for split in ['train']:\n",
        "    # Download the labels\n",
        "    labels_archive = f'{FOLDER_BASE}_{split}_labels.tar.gz'\n",
        "    download_archive(labels_archive)\n",
        "    \n",
        "    # Download Sentinel-1 data\n",
        "    if DOWNLOAD_S1:\n",
        "        s1_archive = f'{FOLDER_BASE}_{split}_source_s1.tar.gz'\n",
        "        download_archive(s1_archive)\n",
        "        \n",
        "\n",
        "    for band, download in DOWNLOAD_BANDS.items():\n",
        "        if not download:\n",
        "            continue\n",
        "        s2_archive = f'{FOLDER_BASE}_{split}_source_s2_{band}.tar.gz'\n",
        "        download_archive(s2_archive)\n",
        "        \n",
        "def resolve_path(base, path):\n",
        "    return Path(os.path.join(base, path)).resolve()\n",
        "        \n",
        "def load_df(collection_id):\n",
        "    split = collection_id.split('_')[-2]\n",
        "    collection = json.load(open(f'{collection_id}/collection.json', 'r'))\n",
        "    rows = []\n",
        "    item_links = []\n",
        "    for link in collection['links']:\n",
        "        if link['rel'] != 'item':\n",
        "            continue\n",
        "        item_links.append(link['href'])\n",
        "        \n",
        "    for item_link in item_links:\n",
        "        item_path = f'{collection_id}/{item_link}'\n",
        "        current_path = os.path.dirname(item_path)\n",
        "        item = json.load(open(item_path, 'r'))\n",
        "        tile_id = item['id'].split('_')[-1]\n",
        "        for asset_key, asset in item['assets'].items():\n",
        "            rows.append([\n",
        "                tile_id,\n",
        "                None,\n",
        "                None,\n",
        "                asset_key,\n",
        "                str(resolve_path(current_path, asset['href']))\n",
        "            ])\n",
        "            \n",
        "        for link in item['links']:\n",
        "            if link['rel'] != 'source':\n",
        "                continue\n",
        "            source_item_id = link['href'].split('/')[-2]\n",
        "            \n",
        "            if source_item_id.find('_s1_') > 0 and not DOWNLOAD_S1:\n",
        "                continue\n",
        "            elif source_item_id.find('_s1_') > 0:\n",
        "                for band in ['VV', 'VH']:\n",
        "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s1/{source_item_id}/{band}.tif').resolve()\n",
        "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
        "                    \n",
        "                    rows.append([\n",
        "                        tile_id,\n",
        "                        f'{date}T00:00:00Z',\n",
        "                        's1',\n",
        "                        band,\n",
        "                        asset_path\n",
        "                    ])\n",
        "                \n",
        "            if source_item_id.find('_s2_') > 0:\n",
        "                for band, download in DOWNLOAD_BANDS.items():\n",
        "                    if not download:\n",
        "                        continue\n",
        "                    \n",
        "                    asset_path = Path(f'{FOLDER_BASE}_{split}_source_s2_{band}/{source_item_id}_{band}.tif').resolve()\n",
        "                    date = '-'.join(source_item_id.split('_')[10:13])\n",
        "                    rows.append([\n",
        "                        tile_id,\n",
        "                        f'{date}T00:00:00Z',\n",
        "                        's2',\n",
        "                        band,\n",
        "                        asset_path\n",
        "                    ])\n",
        "            \n",
        "    return pd.DataFrame(rows, columns=['tile_id', 'datetime', 'satellite_platform', 'asset', 'file_path'])\n",
        "\n",
        "competition_train_df = load_df(f'{FOLDER_BASE}_train_labels')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-dUI1_AzOHw",
        "outputId": "be11f3bf-71f1-4555-c6e0-3536bf6fc070"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1068"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDHGa05LEPJD"
      },
      "source": [
        "# CREATE DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxPaJy6m6EBg"
      },
      "source": [
        "tile_ids_train = competition_train_df['tile_id'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG5fN4cI65qQ"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "import gc\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "harn9qwG65oB"
      },
      "source": [
        "n_obs = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB2CV1T96Uuh"
      },
      "source": [
        "%%time\n",
        "\n",
        "competition_train_df['Month'] = pd.to_datetime(competition_train_df['datetime']).dt.month\n",
        "X = np.empty((0, 12*8),dtype=np.float16)\n",
        "y = np.empty((0, 1),dtype=np.float16)\n",
        "field_ids = np.empty((0, 1),np.float16)\n",
        "\n",
        "for tile_id in tqdm_notebook(tile_ids_train[0:tile_ids_train.shape[0]]):\n",
        "    tile_df = competition_train_df[competition_train_df['tile_id']==tile_id]\n",
        "\n",
        "    label_src = rasterio.open(tile_df[tile_df['asset']=='labels']['file_path'].values[0])\n",
        "    label_array = label_src.read(1).flatten()\n",
        "    \n",
        "    nonzeroidx = np.nonzero(label_array)[0]\n",
        "    \n",
        "    y = np.append(y, label_array[nonzeroidx])\n",
        "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
        "    field_id_array = field_id_src.read(1).flatten()\n",
        "    field_ids = np.append(field_ids, field_id_array[nonzeroidx])\n",
        "\n",
        "    tile_date_times = tile_df[tile_df['satellite_platform']=='s2']['Month'].unique().tolist()\n",
        "    X_tile = np.empty((nonzeroidx.shape[0], 0),dtype=np.float16)\n",
        "    n_X = 0\n",
        "    for date_time_idx in range(0,len(tile_date_times)):\n",
        "\n",
        "        month = tile_date_times[date_time_idx]\n",
        "        # 1. bands arrays :\n",
        "        b1_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B01')]['file_path'].values[2])\n",
        "        b1_array = np.expand_dims(b1_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "        \n",
        "        b2_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B02')]['file_path'].values[2])\n",
        "        b2_array = np.expand_dims(b2_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "        \n",
        "        b3_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B03')]['file_path'].values[2])\n",
        "        b3_array = np.expand_dims(b3_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b4_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B04')]['file_path'].values[2])\n",
        "        b4_array = np.expand_dims(b4_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b5_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B05')]['file_path'].values[2])\n",
        "        b5_array = np.expand_dims(b5_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b6_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B06')]['file_path'].values[2])\n",
        "        b6_array = np.expand_dims(b6_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b7_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B07')]['file_path'].values[2])\n",
        "        b7_array = np.expand_dims(b7_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b8_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B08')]['file_path'].values[2])\n",
        "        b8_array = np.expand_dims(b8_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b8A_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B8A')]['file_path'].values[2])\n",
        "        b8A_array = np.expand_dims(b8A_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b9_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B09')]['file_path'].values[2])\n",
        "        b9_array = np.expand_dims(b9_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b11_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B11')]['file_path'].values[2])\n",
        "        b11_array = np.expand_dims(b11_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        b12_src = rasterio.open(tile_df[(tile_df['Month']==month) & (tile_df['asset']=='B12')]['file_path'].values[2])\n",
        "        b12_array = np.expand_dims(b12_src.read(1).flatten()[nonzeroidx], axis=1)\n",
        "\n",
        "        # X_tile = np.append(X_tile,b2_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b1_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b2_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b3_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b4_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b5_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b6_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b7_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b8_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b8A_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b9_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b11_array,  axis = 1 )\n",
        "        X_tile = np.append(X_tile,b12_array,  axis = 1 )\n",
        "\n",
        "        # del ndvi,gndvi,wdrvi,ndre,evi,savi ,grndvi,ccci\n",
        "        del b1_array,b2_array,b3_array,b4_array,b5_array,b6_array,b7_array,b8_array,b8A_array,b9_array,b11_array,b12_array\n",
        "        del b1_src,b2_src,b3_src,b4_src,b5_src,b6_src,b7_src,b8_src,b8A_src,b9_src,b11_src,b12_src\n",
        "        # if n_X == n_obs:\n",
        "        #     break\n",
        "        \n",
        "    X = np.append(X, X_tile, axis=0)\n",
        "    del X_tile , field_id_array , field_id_src , label_array ,label_src\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nStutoS0Po_N"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pONjdGDAW4BM"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5otf8f9CDM85"
      },
      "source": [
        "data = pd.DataFrame(X)\n",
        "data['label'] = y.astype(int)\n",
        "data['field_id'] = field_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VXCeF0LPLvN"
      },
      "source": [
        "* **Reduce Memory Usage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF8FnGvhPAuF"
      },
      "source": [
        "def reduce_mem_usage(df, verbose=True):\n",
        "  numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "  start_mem = df.memory_usage().sum() / 1024**2\n",
        "  for col in df.columns:\n",
        "      col_type = df[col].dtypes\n",
        "      if col_type in numerics:\n",
        "          c_min = df[col].min()\n",
        "          c_max = df[col].max()\n",
        "          if str(col_type)[:3] == 'int':\n",
        "              if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                  df[col] = df[col].astype(np.int8)\n",
        "              elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                  df[col] = df[col].astype(np.int16)\n",
        "              elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                  df[col] = df[col].astype(np.int32)\n",
        "              elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                  df[col] = df[col].astype(np.int64)\n",
        "          else:\n",
        "              if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                  df[col] = df[col].astype(np.float16)\n",
        "              elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                  df[col] = df[col].astype(np.float32)\n",
        "              else:\n",
        "                  df[col] = df[col].astype(np.float64)\n",
        "\n",
        "  end_mem = df.memory_usage().sum() / 1024**2\n",
        "  print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "  print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UWYy1FHPArw"
      },
      "source": [
        "data = reduce_mem_usage(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNQPTwawf9ul"
      },
      "source": [
        "data = data[data.label != 0] #this filters the pixels that don't have a label (or corresponding field ID)\n",
        "data = reduce_mem_usage(data)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHqXT3FRxeE"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-K4HNAaXYph"
      },
      "source": [
        "# Each field has several pixels in the data. Here our goal is to build a Random Forest (RF) model using the average values\n",
        "# of the pixels within each field. So, we use `groupby` to take the mean for each field_id\n",
        "data_grouped = data.groupby('field_id').mean().reset_index()\n",
        "data_grouped = reduce_mem_usage(data_grouped)\n",
        "data_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn2qm85MVHYr"
      },
      "source": [
        "feat = [\"B1\",\"B2\",\"B3\",\"B4\",\"B5\",\"B6\",\"B7\",\"B8\",\"B8A\",\"B9\",\"B11\",\"B12\"]\n",
        "columns = [x + '_Month4' for x in feat] + [x + '_Month5' for x in feat] + \\\n",
        "          [x + '_Month6' for x in feat] + [x + '_Month7' for x in feat] + \\\n",
        "          [x + '_Month8' for x in feat] + [x + '_Month9' for x in feat] + \\\n",
        "          [x + '_Month10' for x in feat] + [x + '_Month11' for x in feat] \n",
        "columns = ['field_id'] + columns + ['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU-QIMg0V2tU"
      },
      "source": [
        "data_grouped.columns = columns\n",
        "data_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDGsQHL5R7Ip",
        "outputId": "7c5fcbf9-45a3-45c5-c3b7-fc5bafd71015"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtA3TmeUvly"
      },
      "source": [
        "data_grouped.to_csv('TrainObs3.csv',index=False)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth',exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth/Data',exist_ok=True)\n",
        "os.makedirs('/content/drive/MyDrive/RadiantEarth/Data/S2Train',exist_ok=True)\n",
        "\n",
        "!cp 'TrainObs3.csv' \"/content/drive/MyDrive/RadiantEarth/Data/S2Train/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}